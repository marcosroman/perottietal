import random
import glob
import os, os.path
import sys
import itertools # for the cartesian product
from utils import * # some utils, contained in this folder

if len(sys.argv)!=2:
    print "Usage:",sys.argv[0],"<edges file> [assuming <edges file>_oslo_files has already been generated]"
    quit()
else:
    edgesfilename=sys.argv[-1]

N,neighbors=getNneighbors(edgesfilename)
layerbasefilename=edgesfilename+"_oslom2modbp_files/layer"

tpfolder=edgesfilename+"_oslo_files"
assert os.path.exists(tpfolder)
number_of_tp_files=len(glob.glob(tpfolder+"/tp*"))
number_of_layers=number_of_tp_files
# this is the list of layers, as generated by OSLOM2/oslo_undir
tpfiles=[tpfolder+'/tp']+[tpfolder+'/tp'+str(n) for n in range(1,number_of_tp_files)]

# create folder where outputs will be saved
#   (to be saved in modbp format, to make use of the code we have already written, that takes it to nsp format)
layerfolder=edgesfilename+"_oslom2modbp_files"
if not os.path.exists(layerfolder):
    os.makedirs(layerfolder)

modulesperlayerpernode=[[] for i in range(N)] # a list for each node
# now we go layer by layer
tpfiles.reverse() # hago esto asi queda en el orden adecuado, empezando por el layer 1 (convencion modbp), que tendria index zero
for tpindex in range(number_of_tp_files):
    tpfilename=tpfiles[tpindex]

    # open file with module information
    f=open(tpfilename,"r")
    lines=f.readlines()
    # these files contan an even number of lines: for each pair, the first line indicates module number (which is ordered, from 0) and the second one shows the list of nodes... so we need to take the second line and jump every two lines
    filteredlines=lines[1::2]
    listnodespermodule=[]
    for l in filteredlines:
        q=l.split(" ")[:-1]
        s=map(int,q) # s is a list of node labels (integers)
        listnodespermodule.append(s) 

    listmodulespernode=[[] for i_node in range(N)]
    for i_module in range(len(listnodespermodule)): 
        for i_node in listnodespermodule[i_module]:
            listmodulespernode[i_node].append(i_module)

    for i_node in range(N):
        modulesperlayerpernode[i_node].append(listmodulespernode[i_node])
       
# so now, by the end, we must have a full 'modulesperlayerpernode' list (of lists of lists)

# what we're gonna do now, to decide on non-overlapping partitions for each layer, is to get a little bit dirty, a little bit into bruteforce
# because... it seems that oslom may give more than one module per node (at a particular layer), but it may also be that many of these are not contained in modules from the previous layer (that also contain our node) nor do contain modules (again, containing our node) from the next layer. these must be then discarded, so that we may be left with the module(s?) that take part in the hierarchical partitioning
# to do this, the idea is not really complicated, just a bit elaborate (for my tiny brain)

# if we have a well behaved hierarchical partitioning for node 'j', let's say, then it must be that modulesperlayerpernode[j][layer] has just one item per layer: in that case, the cartesian product of [modulesperlayerpernode[j][l] for l in len(number_of_layers)] has just one element: we choose it as the 'path' for node j, that defines a hierarchy of nodes
# now, if we look at some other node, say 'k', is may be that it has more than one module at a certain layer... in that case, the cartesian product of [modulesperlayerpernode[k][l] for l in len(number_of_layers)] (which is written as [p for p in itertools.product(*modulesperlayerpernode[k])]) has more than element --- there's more that one path... so we need to filter out the paths that don't work... if it works, it must be that module p[i] contains module p[i+1] for i=0:(numberoflayers-2).... using what we have defined, this translates to set(getnodesperlayermodule(edgesfilename,i,p[i])).issuperset(getnodesperlayermodule(edgesfilename,i+i,p[i+1]))... and, for a given node, this should be checked for every pair of consecutive layers... perhaps a filter-function is better here
#   let's then define the filter function: it goes for i in range(numberoflayers-1), checks consecutive layers, if fails returns False, if works keeps on working, by the end of the for it shall return True


finalpath=[] # (we need to set this first, as it is also used in the filter function)

def filter_allowed_paths(path):
    for layer_index in range(number_of_layers-1):
        if not set(getnodesperlayermodule(edgesfilename,layer_index,path[layer_index])).issuperset(getnodesperlayermodule(edgesfilename,layer_index+1,path[layer_index+1])):
            return False
    if len(set(finalpath))>0:
        # i'm adding one more thing to check: if the final module already exists in finalpath (as a final module), then it should follow the same path
        for previous_path in set(finalpath):
            for x in range(number_of_layers):
                if previous_path[x] == path[x]: # if last element is same
                    if previous_path[:x] != path[:x] :# if any of the other elements is different
                        return False
    return True

for i in range(N):
    paths=[p for p in itertools.product(*modulesperlayerpernode[i])]
    if len(paths)==1:
        assert len(paths[0])==number_of_layers # just to make sure that foreach node, every layer has an associated module
        finalpath.append(paths[0])
        allowed_paths=paths[0] #useful for debugging purposes only
    else:
        allowed_paths=filter(filter_allowed_paths, paths)
        # aca es donde nos queda hacer lo del scoring...
        # y, al final, el ganador es el que metemos a la lista finalpath

        # so what we do now is to take a score, going from the first layer to the last... we will end up selecting the node that contains the highest amount of neighbors of node i; hence, we will delete from the list paths all other paths in which this condition is not fulfilled... and keep on doing this for the next path, until we get to the final layer OR until we end up with only one path
        for layer_index in range(number_of_layers): # vamos haciendolo por layer, siempre que len(allowed_paths)>1
            possible_modules=list(set([p[layer_index] for p in allowed_paths]))
            if len(possible_modules)==1: # if there's just one possible module in this layer, then just skip to the next layer
                continue
            # this is the score we'll be using: the size of the intersection between a given module and the set of neighbors of node i
            list_size_intersection=[len(set(getnodesperlayermodule(edgesfilename,layer_index,module)).intersection(neighbors[i])) for module in possible_modules]
            max_size_intersection=max(list_size_intersection)
            indices=range(len(list_size_intersection))
            best_modules_indices=filter(lambda x: list_size_intersection[x]==max_size_intersection,indices)
            chosen_module_index=random.choice(best_modules_indices)
            chosen_module=possible_modules[chosen_module_index]
            # and now that we have chosen a module, let's eliminate all paths not having that module at this layer (with index 'layer_index')
            allowed_paths=filter(lambda p: p[layer_index]==chosen_module, allowed_paths)

        finalpath.append(random.choice(allowed_paths))
    print i,"::",finalpath[-1], "(from (possible)",paths," -> (allowed)",allowed_paths


for l in range(number_of_layers):
    f=open(layerbasefilename+"."+str(l+1),'w')
    for i in range(N):
        f.write(str(finalpath[i][l])+"\n")
    f.close()
